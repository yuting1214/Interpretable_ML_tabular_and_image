# Interpretable_ML_tabular_and_image

Implement popular model-agnostic interpretable machine learning methods, LIME and SHAP on the applications of tabular data classficiation and image data classification to delineate models' behaviors and unveil the black box models. 

:question: **Problem:** How to establish an end-to-end data API service for image classification in AWS.

:key: **Importance:** Demonstrate the ability to deploy a data solution by integrating data engineering skills with advanced deep learning techniques.

ðŸŽ‰ **Achievements:** Implemented transfer learning with pre-trained models to accurately classify a diverse set of 133 dog breeds in 90% accuracy, and established an efficient API service in AWS for seamless integration with other applications.

ðŸ’ª **Skills:** Python, Pytorch, AWS SageMaker, Deep learning

:books: **Insights:** The cost-effective way to train, fine-tune, and deploy models in AWS cloud services.

# Problem statement:
What is Interpretability? "Interpretability is the measure of how well a user can correctly and efficiently predict the model's results"

# Models 
## Intrinsically Interpretable Models
* Regression
* Decision Tree

## Model-Agnostic Methods

The benefit of using Model-Agnostic Methods:

The great advantage of model-agnostic interpretation methods over model-specific ones is their flexibility. Machine learning developers are free to use any machine learning model they like when the interpretation methods can be applied to any model. Anything that builds on an interpretation of a machine learning model, such as a graphic or user interface, also becomes independent of the underlying machine learning model.

### Global

* Partial Dependence Plot (PDP):
* Accumulated Local Effects (ALE) Plot:

### Local
* Local Surrogate (LIME)
* Shapley Values

# Applications:

## Tabular data prediction:

Stroke Prediction

### Dataset

### Pipeline

### Result

## Image data classification

### Dataset

### Pipeline

### Result


